---
title: "Text Analyis"
output: github_document
---




# Your mission

Perform text analysis.

## Okay, I need more information

Perform sentiment analysis or topic modeling using text analysis methods as demonstrated in the pre-class work and in the readings.

## Okay, I need even more information.

Do the above. Can't think of a data source?

- `gutenbergr`
- `AssociatedPress` from the `topicmodels` package
- `NYTimes` or `USCongress` from the `RTextTools` package
- Harry Potter Complete 7 Books text
    ```
    if (packageVersion("devtools") < 1.6) {
  install.packages("devtools")
}

devtools::install_github("bradleyboehmke/harrypotter")
    ```
- [State of the Union speeches](https://pradeepadhokshaja.wordpress.com/2017/03/31/scraping-the-web-for-presdential-inaugural-addresses-using-rvest/)
- Scrape tweets using [`twitteR`](https://www.credera.com/blog/business-intelligence/twitter-analytics-using-r-part-1-extract-tweets/)

Analyze the text for sentiment OR topic. **You do not need to do both**. The datacamp courses and [Tidy Text Mining with R](http://tidytextmining.com/) are good starting points for templates to perform this type of analysis, but feel free to *expand beyond these examples*.

# Timelines and Task


We will spend the next 2 weeks working on analyzing textual data in R. You will do the following:

- Start with some text based data.
- Clean data and prepare it for analysis
- Ask questions about the data
- Answer these questions with the data using tables and graphics
- Each group member must have their own unique question that they code the answer for. 


```{r}
install.packages("devtools")
devtools::install_github("bradleyboehmke/harrypotter")
```


#Data cleaning:


```{r}
library(tidytext)
library(dplyr)
library(stringr)
library(harrypotter)
library(ggplot2)
library(tidyr)
```


Do it first for one book: 
```{r}
# Create tibble
data <- tibble(text = half_blood_prince) # column of text
data <- mutate(data, book = "Half Blood Prince")# define a new column for book name
data <- mutate(data, chapter = c(1:nrow(data))) # define a new column for chapter number

head(data)

data %>%
  unnest_tokens(word, text) # Transform the non-tidy text data to tidy text data
```


Generalize this to all books to get dataset of the saga:
```{r}
titles <- c("Philosopher's Stone", "Chamber of Secrets", "Prisoner of Azkaban",
            "Goblet of Fire", "Order of the Phoenix", "Half-Blood Prince",
            "Deathly Hallows")

books <- list(philosophers_stone, chamber_of_secrets, prisoner_of_azkaban,
           goblet_of_fire, order_of_the_phoenix, half_blood_prince,
           deathly_hallows)

saga <- tibble()

for (i in seq_along(titles)) { # create a tibble for each book
  data <- tibble(text = books[[i]]) %>% # add text
    mutate(book = titles[i]) %>% # define a new column for book name
    mutate(chapter = seq_along(books[[i]])) %>% # define a new column for chapter number
    group_by(book) %>% # group by book title
    unnest_tokens(word, text) %>%  # Transform the non-tidy text data to tidy text data
    ungroup()
  
  saga <- rbind(saga, data) # bind rows of tibble of each book
}

saga

```

# Book 2: Chamber of Secrets

```{r}
book2 <- saga %>%
  filter(book=="Chamber of Secrets")
```

## Group questions: 

(1) What is the word count of the book?   
```{r}
nrow(book2)
```

(2) What is the word count of each chapter?
```{r}
book2 %>%
  group_by(chapter) %>%
  count()
```

(2) What are the most common words by chapter?
```{r}
book2 %>% 
  # Use count to find out how many times each word is used
  count(word, sort = TRUE)
```

**find common words that don't include articles**

(3) How does sentiment change across the entire book?
```{r}
count <- book2 %>%
  inner_join(get_sentiments("bing")) %>%  # use bing lexicon to examine sentiment
  group_by(chapter,sentiment) %>%
  count(chapter,sentiment) 

sentiment_prop <- count %>%
  group_by(chapter) %>%
  mutate(total_words=sum(n), prop=n/total_words)
  
# Plot 
ggplot(sentiment_prop, aes(x = chapter, y = prop, col = as.factor(sentiment))) +
  geom_line()
```





```{r}
book2 %>%
  inner_join(get_sentiments("bing")) %>%
  count(chapter, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>%
  # Put index on x-axis, sentiment on y-axis, and map comedy/tragedy to fill
  ggplot(aes(x=chapter, y=sentiment)) +
  # Make a bar chart with geom_col()
  geom_line() +
  # Separate panels for each title with facet_wrap()
  facet_wrap(~ chapter, scales = "free_x")
```




```{r}
book2 %>%
  inner_join(get_sentiments("bing"))  %>% # Implement sentiment analysis with the "bing" lexicon
  group_by(chapter) %>%
  count(sentiment) #%>%
  #filter(sentiment=="negative") %>%
  #arrange(desc(n))


```

(4) Which characters are mentioned the most?




## Individual questions: 

How many times is each word used in the book?
```{r}

```




If I were to start a book club with 10 of my friends who have not read or watch the movies of the Harry Potter Saga, what book should we begin reading? 


Find the percentage of negative words for each chapter.
```{r}
sentiment_counts <- book2 %>%
    # Implement sentiment analysis using the "bing" lexicon
    inner_join(get_sentiments("bing")) %>%
    # Count the number of words by title, type, and sentiment
    count(chapter, sentiment)

sentiment_counts %>%
    # Group by the chapter number
    group_by(chapter) %>%
    # Find the total number of words in each chapter
    mutate(total = sum(n),
    # Calculate the number of words divided by the total
           percent = n/total) %>%
    # Filter the results for only negative sentiment
    filter(sentiment=="negative") %>%
    arrange(desc(percent))
```


Find the percentage of positive words for each chapter.
```{r}
sentiment_counts <- book2 %>%
    # Implement sentiment analysis using the "bing" lexicon
    inner_join(get_sentiments("bing")) %>%
    # Count the number of words by title, type, and sentiment
    count(chapter, sentiment)

sentiment_counts %>%
    # Group by the chapter number
    group_by(chapter) %>%
    # Find the total number of words in each chapter
    mutate(total = sum(n),
    # Calculate the number of words divided by the total
           percent = n/total) %>%
    # Filter the results for only negative sentiment
    filter(sentiment=="positive") %>%
    arrange(desc(percent))
```


Calculate net sentiment: 
```{r}
library(tidyr)

book2 %>%
  inner_join(get_sentiments("bing")) %>%
  count(chapter, sentiment) %>%
  # Spread sentiment and n across multiple columns
  spread(sentiment, n, fill = 0) %>%
  # Use mutate to find net sentiment
  mutate(sentiment = positive-negative)

```


```{r}
book2 %>%
  inner_join(get_sentiments("bing")) %>%
  count(chapter, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>%
  # Put index on x-axis, sentiment on y-axis, and map comedy/tragedy to fill
  ggplot(aes(x=chapter, y=sentiment, fill=type)) +
  # Make a bar chart with geom_col()
  geom_col() +
  # Separate panels for each title with facet_wrap()
  facet_wrap(~ title, scales = "free_x")
```


(4) Which characters are mentioned the most? 
```{r}

```




(5) How does the emotion "anticipation" change throughtout the book?
```{r}

```





