---
title: "Text Analyis"
output: github_document
---




# Your mission

Perform text analysis.

## Okay, I need more information

Perform sentiment analysis or topic modeling using text analysis methods as demonstrated in the pre-class work and in the readings.

## Okay, I need even more information.

Do the above. Can't think of a data source?

- `gutenbergr`
- `AssociatedPress` from the `topicmodels` package
- `NYTimes` or `USCongress` from the `RTextTools` package
- Harry Potter Complete 7 Books text
    ```
    if (packageVersion("devtools") < 1.6) {
  install.packages("devtools")
}

devtools::install_github("bradleyboehmke/harrypotter")
    ```
- [State of the Union speeches](https://pradeepadhokshaja.wordpress.com/2017/03/31/scraping-the-web-for-presdential-inaugural-addresses-using-rvest/)
- Scrape tweets using [`twitteR`](https://www.credera.com/blog/business-intelligence/twitter-analytics-using-r-part-1-extract-tweets/)

Analyze the text for sentiment OR topic. **You do not need to do both**. The datacamp courses and [Tidy Text Mining with R](http://tidytextmining.com/) are good starting points for templates to perform this type of analysis, but feel free to *expand beyond these examples*.

# Timelines and Task


We will spend the next 2 weeks working on analyzing textual data in R. You will do the following:

- Start with some text based data.
- Clean data and prepare it for analysis
- Ask questions about the data
- Answer these questions with the data using tables and graphics
- Each group member must have their own unique question that they code the answer for. 

```{r}
library(tidytext)
library(rebus)
library(stringi)
library(stringr)
library(harrypotter)

bing=get_sentiments("bing")

titles <- c("Philosopher's Stone", "Chamber of Secrets", "Prisoner of Azkaban",
            "Goblet of Fire", "Order of the Phoenix", "Half-Blood Prince",
            "Deathly Hallows")
  
books <- list(philosophers_stone , chamber_of_secrets, prisoner_of_azkaban,
           goblet_of_fire, order_of_the_phoenix, half_blood_prince,
           deathly_hallows
           )

series <- tibble()

for(l in 1:seq_along(books)){
  for(i in 1:seq_along(books[l]))
   clean= tibble(txt=books[l][[i]]) 
   clean %>% mutate(title=titles[l], chapter=i) %>% unnest_tokens(word, txt, to_lower=F) 
  series <- rbind(series, clean)
}



```


```{r}
#Questions:
#(1) How the sentiment changes across the entire book
#(2) WHat are the most common words by chapter
#(3) Which characters appear the most 
#(4) How the emotion anticipation changes throughtout the book
#(5) Word count for each book

library(plyr)
library(dplyr)
library(tidytext)
library(stringr)
library(ggplot2)
library(harrypotter)
library(rebus)

book_names <- list(philosophers_stone, chamber_of_secrets, prisoner_of_azkaban, goblet_of_fire, order_of_the_phoenix, half_blood_prince, deathly_hallows)

names(book_names) <- c("philosophers_stone", "chamber_of_secrets", "prisoner_of_azkaban", "goblet_of_fire", "order_of_the_phoenix", "half_blood_prince", "deathly_hallows")

books = vector(mode = "list", length = 7)
for(i in 1:length(books)){
  data <- data_frame(text = book_names[[i]])
  data <- mutate(data, chapter = c(1:nrow(data)), title = names(book_names)[i])
  data <- data %>%
    unnest_tokens(word, text, to_lower = TRUE)
  books[[i]] <- data
}

#Carol-Goblet of Fire:
#(1) How the sentiment changes across the entire book
bing <- get_sentiments("bing")
cs_book= books[[4]]
sentiment_4=inner_join(cs_book, bing)
percents <- sentiment_4 %>% dplyr::group_by(chapter) %>% dplyr::count(sentiment) %>% dplyr:: mutate(total_words=sum(n))


ggplot(percents, aes(x = chapter, y = percent, col = as.factor(sentiment))) +
  geom_line()


#(2) What are the most common words by chapter
stop=c(stopwords("en"), 'said', 'mr', 'mrs', 'he', 'she', 'it', 'they', 'i', 'you', 'professor')
comm_words<-cs_book %>% dplyr::filter(!word %in% stop) %>% dplyr::group_by(chapter) %>% dplyr::count(word) %>% dplyr::arrange(desc(n))


#(3) Which characters appear the most 
books = vector(mode = "list", length = 7)
for(i in 1:length(books)){
  data <- data_frame(text = book_names[[i]])
  data <- mutate(data, chapter = c(1:nrow(data)), title = names(book_names)[i])
  data <- data %>%
    unnest_tokens(word, text, to_lower = F)
  books[[i]] <- data
}
cap_stop=stri_trans_totitle(stop)
pattern1=START %R% UPPER %R% optional(zero_or_more(ANY_CHAR) %R% SPC %R% UPPER)
Char_4<-str_subset(books[[4]]$word, pattern=pattern1)
char_list<-data_frame(word=Char_4) %>% filter(!word %in% cap_stop) %>% unique()
char_list_2<-right_join(books[[4]], char_list) %>% dplyr::count(word) %>% dplyr::arrange(desc(n))

#(4) How the emotion anticipation changes throughtout the book
nrc <- get_sentiments("nrc") %>% filter(sentiment=='anticipation')
cs_book= books[[4]]
anti_4=inner_join(cs_book, nrc)
percents_4 <- anti_4 %>% dplyr::group_by(chapter) %>% dplyr::count(sentiment) %>% dplyr:: mutate(total_words=sum(n))

#(5) Word count for each book
word_count<-cs_book %>% dplyr::summarise(total_words=n())

```

