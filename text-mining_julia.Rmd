---
title: "Text Analyis"
output: github_document
---




# Your mission

Perform text analysis.

## Okay, I need more information

Perform sentiment analysis or topic modeling using text analysis methods as demonstrated in the pre-class work and in the readings.

## Okay, I need even more information.

Do the above. Can't think of a data source?

- `gutenbergr`
- `AssociatedPress` from the `topicmodels` package
- `NYTimes` or `USCongress` from the `RTextTools` package
- Harry Potter Complete 7 Books text
    ```
    if (packageVersion("devtools") < 1.6) {
  install.packages("devtools")
}

devtools::install_github("bradleyboehmke/harrypotter")
    ```
- [State of the Union speeches](https://pradeepadhokshaja.wordpress.com/2017/03/31/scraping-the-web-for-presdential-inaugural-addresses-using-rvest/)
- Scrape tweets using [`twitteR`](https://www.credera.com/blog/business-intelligence/twitter-analytics-using-r-part-1-extract-tweets/)

```{r}
install.packages("devtools")
devtools::install_github("bradleyboehmke/harrypotter")
```

```{r}
library(harrypotter)
?harrypotter
#How the sentiment changes across the entire book
#What are the most common words by chapter
#Which characters appear the most 
#How the emotion anticipation changes throughtout the book
#Word count for each book
```

Analyze the text for sentiment OR topic. **You do not need to do both**. The datacamp courses and [Tidy Text Mining with R](http://tidytextmining.com/) are good starting points for templates to perform this type of analysis, but feel free to *expand beyond these examples*.

# Timelines and Task


We will spend the next 2 weeks working on analyzing textual data in R. You will do the following:

- Start with some text based data.
- Clean data and prepare it for analysis
```{r}
library(tidytext)
library(plyr)
library(dplyr)
library(stringr)
library(ggplot2)
#clean the data
#make a list of book names
book_names <- list(philosophers_stone, chamber_of_secrets, prisoner_of_azkaban, goblet_of_fire, order_of_the_phoenix, half_blood_prince, deathly_hallows)
#concatenate a vector of names
names(book_names) <- c("philosophers_stone", "chamber_of_secrets", "prisoner_of_azkaban", "goblet_of_fire", "order_of_the_phoenix", "half_blood_prince", "deathly_hallows")

books = vector(mode = "list", length = 7)
#create a for loop to go through the chapters of the books and unnest the text into words
for(i in 1:length(books)){
  data <- data_frame(text = book_names[[i]])
  data <- mutate(data, chapter = c(1:nrow(data)), title = names(book_names)[i])
  data <- data %>%
    unnest_tokens(word, text, to_lower = TRUE)
  books[[i]] <- data
}
#new dataset books
books <- ldply(books, data.frame)
```

- Ask questions about the data
```{r}
#word count for each book
books%>%
  filter(title == "philosophers_stone")%>%
  group_by(chapter)%>%
  count()
  
```
```{r}
#most common words by chapter
```

```{r}
books%>%
inner_join(get_sentiments("bing"))%>%
group_by(chapter)%>%
count(sentiment)%>%
filter(sentiment=="positive")

```

- Answer these questions with the data using tables and graphics
- Each group member must have their own unique question that they code the answer for. 

